{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc53cf19-f12c-4977-87cf-595999988ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from data import *\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji    # removes emojis\n",
    "import re   # removes links\n",
    "import en_core_web_sm\n",
    "import string\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fe9d37-605c-4bb9-90a0-0e04dccc307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Venetis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Venetis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "nltk.downloader.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b069e45-9e24-43ad-8194-48b050cb3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(user_agent=\"###\",\n",
    "                         client_id=\"###\",\n",
    "                         client_secret=\"###\",\n",
    "                         username=\"###\",\n",
    "                         password=\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96af958d-0fb2-45a1-8d99-9500d796a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####get daily and weekly trends\n",
    "def data_extractor_daily_and_week(reddit,no_posts):\n",
    "    '''extracts daily and weekly mentioned tickers\n",
    "    Parameter: reddt: reddit obj\n",
    "               no_posts: number of posts that will be searched #200 and 500 are ok\n",
    "    Return:   check the return section for more information\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    ##################################\n",
    "    #Initialization\n",
    "    subs = ['wallstreetbets',\"stocks\",\"stock_picks\",\"spacs\",\"pennystocks\",\"finance\",\"financialindependence\",\"options\",\"investing\",\"forex\",\"stockmarket\",\"Shortsqueeze\" ]     # sub-reddit to search\n",
    "\n",
    "    \n",
    "    # post will be considered if it satisfies the following requirements\n",
    "    #upvotes = [0,0.3,0.5,0.7]\n",
    "    #ups = [0,20,200,500]\n",
    "    upvotes = [0]\n",
    "    ups = [0]\n",
    "    \n",
    "    ################################### \n",
    "    #Return Items\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    #weekly\n",
    "    titles = {} #a dict that contains all the titles for the given subreddit and filtering combination\n",
    "    #titles = {\"wsb\":{(0,0):[],(0,20):[]}} #key1 subreddit #key2 filtering combination, value a list that contains the titles\n",
    "    #tiles[sub]=defaultdict(list)\n",
    "    \n",
    "    tickers = defaultdict(lambda: defaultdict(int)) #remove two # to use it\n",
    "    # a dict that contains all the ticks, for the given post filtering combinations, the value is the no appearances\n",
    "    #ticks = {(0,0):{\"TSLA\":#count, \"APPL\":#count }, (0,20):{\"TSLA\":#count, \"APPL\":#count }}\n",
    "    #key1 filtering combination #key2 stock , value is the #count of the tick\n",
    "    \n",
    "    tick_comments = defaultdict(lambda: defaultdict(list))\n",
    "    #similar structure as the tickers but the value is the actual comments that correspond to that tick\n",
    "    tick_dates = defaultdict(lambda: defaultdict(list))\n",
    "    #similar strucutre as the tickers but the value is the date the comment was made\n",
    "    \n",
    "    \n",
    "    #daily\n",
    "    titles_d = {} #a dict that contains all the titles for the given subreddit and filtering combination\n",
    "    #titles = {\"wsb\":{(0,0):[],(0,20):[]}} #key1 subreddit #key2 filtering combination, value a list that contains the titles\n",
    "    #tiles[sub]=defaultdict(list)\n",
    "    \n",
    "    tickers_d = defaultdict(lambda: defaultdict(int)) #remove two # to use it\n",
    "    # a dict that contains all the ticks, for the given post filtering combinations, the value is the no appearances\n",
    "    #ticks = {(0,0):{\"TSLA\":#count, \"APPL\":#count }, (0,20):{\"TSLA\":#count, \"APPL\":#count }}\n",
    "    #key1 filtering combination #key2 stock , value is the #count of the tick\n",
    "    \n",
    "    tick_comments_d = defaultdict(lambda: defaultdict(list))\n",
    "    #similar structure as the tickers but the value is the actual comments that correspond to that tick\n",
    "    tick_dates_d = defaultdict(lambda: defaultdict(list))\n",
    "    #similar strucutre as the tickers but the value is the date the comment was made\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################################################################\n",
    "    for sub in subs:\n",
    "        start = time.time() #time it took for on subreddit comment extraction\n",
    "        print(sub)\n",
    "        \n",
    "        #### subreddit selection\n",
    "        subreddit = reddit.subreddit(sub) #select the subreddit\n",
    "        #titles[sub]=defaultdict(list)\n",
    "        \n",
    "        \n",
    "        ###### itterate through the posts\n",
    "\n",
    "        hot_posts = subreddit.hot( limit=no_posts)\n",
    "        for post in hot_posts:\n",
    "            try:\n",
    "                flair = post.link_flair_text #flair tags, they explain\n",
    "                author = post.author.name   #post author\n",
    "                post_text = post.selftext   #actual post (text)\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            #post info has issue skip\n",
    "            #i can use continue to bypass the for itteration\n",
    "              \n",
    "            \n",
    "            \n",
    "            post.comment_sort = 'hot'   #keep the most \"hot\" comments\n",
    "            comments = post.comments #comments of that post\n",
    "            \n",
    "            #get more comments\n",
    "            try:\n",
    "                post.comments.replace_more(limit=5)   #might not be possible to replace that many\n",
    "            except:\n",
    "                try:\n",
    "                    post.comments.replace_more(limit=3)   #might not be possible to replace that many\n",
    "                except:\n",
    "                    try:\n",
    "                        post.comments.replace_more(limit=1)   #might not be possible to replace that many\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "             \n",
    "            \n",
    "            #itterate through various filtering methods\n",
    "            #upvotes = [0,0.3,0.50.7]\n",
    "            #ups = [0,20,200,500]\n",
    "                \n",
    "            for upv in upvotes:\n",
    "                for up in ups:\n",
    "                    #keep posts that satisfy the min requirements bellow\n",
    "                    if post.upvote_ratio >= upv and post.ups > up: \n",
    "                                                                              \n",
    "                        #comment extraction \n",
    "                        \n",
    "                        for comment in comments:\n",
    "                            \n",
    "                            try: #deleted comment, skip\n",
    "                                auth = comment.author.name #if deleted this would give an error\n",
    "                            except:\n",
    "                                continue #skip comment if it is deleted\n",
    "                                \n",
    "                            time_creation = (time.time()- comment.created_utc)/60/60/24\n",
    "                            \n",
    "                            #weekly and daily after middle of function\n",
    "                            if float(time_creation)<=7 : \n",
    "                                split = comment.body.split(\" \") #split comment to words\n",
    "                                for word in split:\n",
    "                                    word = word.replace(\"$\", \"\") \n",
    "\n",
    "                                    #stocks tickers are capitals and less or equal than 5 letters\n",
    "                                    #we also check if the tick is inside the stock lists \"us\"\n",
    "                                    if word.isupper() and len(word) <= 5 and word not in blacklist and word in us:\n",
    "\n",
    "                                        tickers[(upv,up)][word] = tickers[(upv,up)][word] + 1 #no appearances for the given tick\n",
    "\n",
    "                                        #further filter by date #could be done in the dataframe?\n",
    "                                        tick_comments[(upv,up)][word].append(comment.body) \n",
    "                                        #comment related to that tick\n",
    "                                        tick_dates[(upv,up)][word].append(datetime.fromtimestamp(comment.created_utc))\n",
    "                                        #date the comment was posted\n",
    "                                        \n",
    "                                        #daily  \n",
    "                                        if float(time_creation)<=1:\n",
    "                                            \n",
    "                                            tickers_d[(upv,up)][word] = tickers_d[(upv,up)][word] + 1 #no appearances for the given tick\n",
    "\n",
    "                                            #further filter by date #could be done in the dataframe?\n",
    "                                            tick_comments_d[(upv,up)][word].append(comment.body) \n",
    "                                            #comment related to that tick\n",
    "                                            tick_dates_d[(upv,up)][word].append(datetime.fromtimestamp(comment.created_utc))\n",
    "                                            #date the comment was posted\n",
    "                                        \n",
    "                            \n",
    "                                        \n",
    "                                        \n",
    "\n",
    "        end = time.time()\n",
    "        print(\"time\",(end - start)/60)\n",
    "        \n",
    "        \n",
    "                \n",
    "    return tick_comments, tick_dates, tickers, tickers_d, tick_comments_d, tick_dates_d            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df1eef7-1b50-4973-a29a-d8b76fd0caf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wallstreetbets\n",
      "time 9.780030655860902\n",
      "stocks\n",
      "time 8.410535824298858\n",
      "stock_picks\n",
      "time 3.7956371903419495\n",
      "spacs\n",
      "time 11.347148803869883\n",
      "pennystocks\n",
      "time 6.998927319049836\n",
      "finance\n",
      "time 5.818339415391287\n",
      "financialindependence\n",
      "time 14.45028451681137\n",
      "options\n",
      "time 9.454303336143493\n",
      "investing\n",
      "time 4.300775929292043\n",
      "forex\n",
      "time 8.71840387582779\n",
      "stockmarket\n",
      "time 6.313835084438324\n",
      "Shortsqueeze\n",
      "time 8.511406175295512\n"
     ]
    }
   ],
   "source": [
    "tick_comments, tick_dates, tickers, tickers_d, tick_comments_d, tick_dates_d  = data_extractor_daily_and_week(reddit,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52d94434-ee47-438e-b9b2-3b09354856ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n_stocks(stock_count,n,min_no_com):\n",
    "    '''\n",
    "    Input: \n",
    "    stock_count: dictionary that has the name of the stock as key and the number of appearances for that stock is the key\n",
    "    n: number of stock with the highest count that will be selected\n",
    "    min_no_com: minimum number of comments/mentions needed in order to include that stock #20 for daily #100 weekly \n",
    "    \n",
    "    Output \n",
    "    ret: a list that contains the n most mentioned stocks\n",
    "    '''\n",
    "    sorted_dict = dict(sorted(stock_count.items(), key=lambda item: item[1], reverse=True))\n",
    "    ret = []\n",
    "    for stck in sorted_dict.keys():\n",
    "        if sorted_dict[stck]>=min_no_com:\n",
    "            ret.append(stck)\n",
    "    return ret[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a9911c8-28a6-4fa8-97ca-1e1260f37031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily ticks: ['CRTX', 'AAPL', 'GME', 'AMD', 'TSLA', 'BABA', 'NUZE', 'PLTR', 'SI', 'PROG', 'DKNG', 'WISH', 'MSFT', 'FB', 'NVDA']\n",
      "Weekly ticks: ['AAPL', 'AMD', 'GME', 'NVDA', 'TSLA', 'BABA', 'MRNA', 'WISH', 'MSFT', 'CRTX', 'PLTR', 'DIS', 'F', 'PYPL', 'PE']\n"
     ]
    }
   ],
   "source": [
    "daily_ticks = find_top_n_stocks(tickers_d[(0,0)],15,20)\n",
    "print(f\"Daily ticks: {daily_ticks}\")\n",
    "weekly_ticks = find_top_n_stocks(tickers[(0,0)],15,50)\n",
    "print(f\"Weekly ticks: {weekly_ticks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdc41be2-db7c-4b5a-822a-05fb4cecf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_top_trenders(daily_ticks,weekly_ticks,save):\n",
    "    #save: represents whether u want the df to be saved as a csv too (True or False)\n",
    "    #returns a dataframe that contains the daily and weekly trenders\n",
    "    d = {\"daily_trenders\":daily_ticks,\"weekly_trenders\":weekly_ticks}\n",
    "    df = pd.DataFrame(d)\n",
    "    if save==True:\n",
    "        df.to_csv(\"daily_weekly_trending_stocks.csv\", index=False)        \n",
    "    return df\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "705bcf78-d0fe-446c-8299-8b6fc51866a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_trenders</th>\n",
       "      <th>weekly_trenders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRTX</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>AMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GME</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BABA</td>\n",
       "      <td>BABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NUZE</td>\n",
       "      <td>MRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>WISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SI</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PROG</td>\n",
       "      <td>CRTX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DKNG</td>\n",
       "      <td>PLTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WISH</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FB</td>\n",
       "      <td>PYPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   daily_trenders weekly_trenders\n",
       "0            CRTX            AAPL\n",
       "1            AAPL             AMD\n",
       "2             GME             GME\n",
       "3             AMD            NVDA\n",
       "4            TSLA            TSLA\n",
       "5            BABA            BABA\n",
       "6            NUZE            MRNA\n",
       "7            PLTR            WISH\n",
       "8              SI            MSFT\n",
       "9            PROG            CRTX\n",
       "10           DKNG            PLTR\n",
       "11           WISH             DIS\n",
       "12           MSFT               F\n",
       "13             FB            PYPL\n",
       "14           NVDA              PE"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trenders(daily_ticks,weekly_ticks,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e71b149b-23e0-4968-a998-94b7a5e38dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_to_df(top_ticks,tick_comments,tick_dates,save,time):\n",
    "    #restructures dictionaries to useful dataframe format\n",
    "    #save indicates whether we want to save the dataframe\n",
    "    #daily or weekly indicate what your csv represents\n",
    "    d = {\"tick\":[],\"comment\":[],\"date\":[]}\n",
    "    for tick in top_ticks:\n",
    "        for i in range(len(tick_comments[tick])):\n",
    "            d[\"tick\"].append(tick)\n",
    "            d[\"comment\"].append(tick_comments[tick][i])\n",
    "            d[\"date\"].append(tick_dates[tick][i])\n",
    "    df = pd.DataFrame(d)\n",
    "    \n",
    "     \n",
    "    if save==True:\n",
    "        df.to_csv(f\"{time}_ticks_comments.csv\", index=False)        \n",
    "    return df\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a9d0113-25b0-4b67-91ea-f0203d2558ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tick</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>So AAPL reached ATH and decided to drop 10 buc...</td>\n",
       "      <td>2021-12-02 08:28:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL dropped fluff news about their car before...</td>\n",
       "      <td>2021-12-02 07:25:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL looking like the russel false breakout.  ...</td>\n",
       "      <td>2021-12-02 06:35:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Bought AAPL 12/10 170p yesterday when it was A...</td>\n",
       "      <td>2021-12-02 07:28:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>So, the megachamp AAPL thatâ€™s been propping up...</td>\n",
       "      <td>2021-12-02 07:32:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>PE</td>\n",
       "      <td>Filtering using PE leads to some misconception...</td>\n",
       "      <td>2021-11-25 12:04:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>PE</td>\n",
       "      <td>Filtering using PE leads to some misconception...</td>\n",
       "      <td>2021-11-25 12:04:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>PE</td>\n",
       "      <td>Filtering using PE leads to some misconception...</td>\n",
       "      <td>2021-11-25 12:04:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>PE</td>\n",
       "      <td>I mean, how many of these are in industries wh...</td>\n",
       "      <td>2021-11-25 12:08:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>PE</td>\n",
       "      <td>Maybe they should make profit, have a low PE a...</td>\n",
       "      <td>2021-11-25 19:31:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2141 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tick                                            comment  \\\n",
       "0     AAPL  So AAPL reached ATH and decided to drop 10 buc...   \n",
       "1     AAPL  AAPL dropped fluff news about their car before...   \n",
       "2     AAPL  AAPL looking like the russel false breakout.  ...   \n",
       "3     AAPL  Bought AAPL 12/10 170p yesterday when it was A...   \n",
       "4     AAPL  So, the megachamp AAPL thatâ€™s been propping up...   \n",
       "...    ...                                                ...   \n",
       "2136    PE  Filtering using PE leads to some misconception...   \n",
       "2137    PE  Filtering using PE leads to some misconception...   \n",
       "2138    PE  Filtering using PE leads to some misconception...   \n",
       "2139    PE  I mean, how many of these are in industries wh...   \n",
       "2140    PE  Maybe they should make profit, have a low PE a...   \n",
       "\n",
       "                    date  \n",
       "0    2021-12-02 08:28:02  \n",
       "1    2021-12-02 07:25:08  \n",
       "2    2021-12-02 06:35:51  \n",
       "3    2021-12-02 07:28:53  \n",
       "4    2021-12-02 07:32:39  \n",
       "...                  ...  \n",
       "2136 2021-11-25 12:04:29  \n",
       "2137 2021-11-25 12:04:29  \n",
       "2138 2021-11-25 12:04:29  \n",
       "2139 2021-11-25 12:08:25  \n",
       "2140 2021-11-25 19:31:10  \n",
       "\n",
       "[2141 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_to_df(weekly_ticks,tick_comments[(0,0)],tick_dates[(0,0)],True,\"weekly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3279709b-c51d-45f2-8b49-22497c14f039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tick</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRTX</td>\n",
       "      <td>Ask all the people who sold CRTX puts in Octob...</td>\n",
       "      <td>2021-12-02 09:41:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRTX</td>\n",
       "      <td>https://www.marketwatch.com/tools/screener/sho...</td>\n",
       "      <td>2021-12-02 08:06:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRTX</td>\n",
       "      <td>The only thing with CRTX is that the shorts en...</td>\n",
       "      <td>2021-12-02 09:12:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRTX</td>\n",
       "      <td>CRTX to the moon!</td>\n",
       "      <td>2021-12-01 16:08:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRTX</td>\n",
       "      <td>CRTX ðŸš€ðŸš€ðŸš€ðŸš€ðŸŒšðŸŒšðŸŒšðŸŒš</td>\n",
       "      <td>2021-12-01 17:48:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>META / AMD / NVDA  \\n\\n\\n\\*Shareholder</td>\n",
       "      <td>2021-12-02 06:42:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>Weird how AMD and NVDA are going down.  I am n...</td>\n",
       "      <td>2021-12-01 13:14:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>Weird how AMD and NVDA are going down.  I am n...</td>\n",
       "      <td>2021-12-01 13:14:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>I thought the same thing half a year ago. I am...</td>\n",
       "      <td>2021-12-01 19:39:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>No.\\n\\nBuy NVDA instead.</td>\n",
       "      <td>2021-12-02 00:01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tick                                            comment  \\\n",
       "0    CRTX  Ask all the people who sold CRTX puts in Octob...   \n",
       "1    CRTX  https://www.marketwatch.com/tools/screener/sho...   \n",
       "2    CRTX  The only thing with CRTX is that the shorts en...   \n",
       "3    CRTX                                  CRTX to the moon!   \n",
       "4    CRTX                                      CRTX ðŸš€ðŸš€ðŸš€ðŸš€ðŸŒšðŸŒšðŸŒšðŸŒš   \n",
       "..    ...                                                ...   \n",
       "547  NVDA             META / AMD / NVDA  \\n\\n\\n\\*Shareholder   \n",
       "548  NVDA  Weird how AMD and NVDA are going down.  I am n...   \n",
       "549  NVDA  Weird how AMD and NVDA are going down.  I am n...   \n",
       "550  NVDA  I thought the same thing half a year ago. I am...   \n",
       "551  NVDA                           No.\\n\\nBuy NVDA instead.   \n",
       "\n",
       "                   date  \n",
       "0   2021-12-02 09:41:17  \n",
       "1   2021-12-02 08:06:11  \n",
       "2   2021-12-02 09:12:46  \n",
       "3   2021-12-01 16:08:45  \n",
       "4   2021-12-01 17:48:05  \n",
       "..                  ...  \n",
       "547 2021-12-02 06:42:34  \n",
       "548 2021-12-01 13:14:29  \n",
       "549 2021-12-01 13:14:29  \n",
       "550 2021-12-01 19:39:10  \n",
       "551 2021-12-02 00:01:14  \n",
       "\n",
       "[552 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_to_df(daily_ticks,tick_comments_d[(0,0)],tick_dates_d[(0,0)],True,\"daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f30e9b-afff-4163-98eb-ab4cee09ba32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87abd1a-95cb-4f6c-ae31-4ce103824f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a42df-383c-4233-ba89-1b2986ec34a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174ea15-9202-4c10-9d40-70208141b2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc893c-84f9-42c9-bcbb-fbb322e378cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIA.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05005b9d-76c3-4f44-a909-7512bd8a089b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792dcbd0-c060-443c-aaff-d98c9de1df6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2e68c-4168-4155-8536-282809ecf612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
